{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyML keyword spotting helper functions\n",
    "Some functions useful for handling audio data, used in TinyML keyword spotting exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV file converter\n",
    "\n",
    "\n",
    "Convert WAV files to a chosen sample rate (`resampled_sr`) and/or to `mono`.\n",
    "\n",
    "How to use:\n",
    "\n",
    "```python\n",
    "wave_converter('my_file1.wav', mix2mono = True)\n",
    "'''output file \"resampled_my_file1.wav\", mono, 16000 Hz sample rate'''\n",
    "\n",
    "wave_converter('my_file2.wav', resampled_sr = 8000, prefix = \"small_\")\n",
    "'''output file \"small_my_file2.wav\", 8000 Hz sample rate, number of channels unchanged (e.g. a stereo file\n",
    "will remain stereo)'''\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "import librosa\n",
    "\n",
    "def wave_converter(filename, resampled_sr=16000, prefix=\"resampled_\", mix2mono = False):\n",
    "\n",
    "    '''\n",
    "    Resample WAV soundfile to a different sample rate.\n",
    "    \n",
    "        Input: original sound file\n",
    "        Output: resampled sound file\n",
    "        Parameters: \n",
    "            - name of the file to be converted, \n",
    "            - destination sample rate, default = 16kHz\n",
    "            - prefix to identify resampled files\n",
    "            - mix to mono channel, default = False (leave as-is)\n",
    "            \n",
    "        Notes: for simplicity it needs to be run in the folder with the files we are converting\n",
    "    '''    \n",
    "    \n",
    "    resampled_file = prefix + filename \n",
    "    origin_sr, origin_data = wavfile.read(filename)\n",
    "    origin_type = origin_data.dtype\n",
    "    \n",
    "    resampled_data = librosa.resample(origin_data.T.astype('float'), origin_sr, resampled_sr) # transpose array to librosa shape\n",
    "    if mix2mono == True:\n",
    "        resampled_data = librosa.to_mono(resampled_data)        \n",
    "    resampled_data = resampled_data.T.astype(origin_type) # transpose back to scipy.io.wavfile shape\n",
    "    \n",
    "    wavfile.write(resampled_file, resampled_sr, resampled_data)\n",
    "    \n",
    "    print('Resampled wavefile saved to {}'.format(resampled_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio file\n",
    "\n",
    "As I was having some problems with the HTML audio recoding code, I recorded my keyword samples with Audacity, \n",
    "and then upload them with this little snippet.\n",
    "\n",
    "How to use: \n",
    "\n",
    "```python\n",
    "audio, sr = get_audio('my_file.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as wav_read\n",
    "def get_audio(file):\n",
    "    '''return sample rate and audio data'''\n",
    "    sr, audio = wav_read(file)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch inference testing\n",
    "\n",
    "Helper function for testing your own audio samples with the model here:\n",
    "\n",
    "https://github.com/tinyMLx/colabs/blob/master/3-5-13-PretrainedModel.ipynb\n",
    "\n",
    "\n",
    "__Assumptions:__\n",
    "\n",
    "* your samples are saved in a folder, and the file names follow a specific pattern `audio_a_cat01.wav`: \n",
    "    * `a` is the speaker identifier, \n",
    "    * `cat` is the actual keyword, \n",
    "    * `01` is the sample number, assuming we have multiple samples for each word.\n",
    "\n",
    "* `run_tflite_inference_singleFile` function, `WANTED_WORDS` and `MODEL_TFLITE` variables are already defined.\n",
    "\n",
    "* `run_tflite_inference_singleFile` function is modified to return the top_prediction_str and model_type variables:\n",
    "\n",
    "```python\n",
    "def run_tflite_inference_singleFile(tflite_model_path, custom_audio, sr_custom_audio, model_type=\"Float\"):\n",
    "  \n",
    "  # (function code here) \n",
    "  #  \n",
    "  # print('%s model guessed the value to be %s' % (model_type, top_prediction_str))\n",
    "\n",
    "  return model_type, top_prediction_str # used in the batch script later\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"Quantized\"\n",
    "\n",
    "SPEAKERS = {'a': 'Alice', 'b': 'Bob'}\n",
    "\n",
    "SAMPLES_DIR = 'speech_custom'\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "for file in os.listdir(SAMPLES_DIR):\n",
    "    if os.path.isdir(file): # skip folders, process files only \n",
    "        pass\n",
    "    else:                        \n",
    "        try:\n",
    "            speaker, word, number = re.findall('custom_(\\w)_([a-z]+)(\\d+).wav', file)[0] # extract info                                    \n",
    "        except:\n",
    "            print(\"File name {} is not in a correct format\".format(file))\n",
    "            # pass\n",
    "        sample_name = file[:-4] # create variable names\n",
    "        sample_rate = 'sr_' + sample_name # create variable names\n",
    "        globals()[sample_name], globals()[sample_rate] = get_audio(os.path.join(SAMPLES_DIR, file)) # define variables\n",
    "        \n",
    "        if word in [word for word in WANTED_WORDS.split(',')]: # WANTED_WORDS and MODEL_TFLITE defined earlier\n",
    "    \n",
    "            model_type, top_prediction_str = run_tflite_inference_singleFile(MODEL_TFLITE, globals()[sample_name], globals()[sample_rate], model_type=MODEL_TYPE)\n",
    "        \n",
    "            if top_prediction_str.upper() == word.upper():\n",
    "                result = \"CORRECTLY\"\n",
    "            else:\n",
    "                result = \"INCORRECTLY\"\n",
    "                        \n",
    "            print('\\nWord: {},\\nSpeaker: {},\\nSample number: {},\\nFile: {}'.format(word.upper(), speakers[speaker], number, file))\n",
    "        \n",
    "            print(\"\\n{} model guessed the value to be {}.\".format(model_type, top_prediction_str.upper()))\n",
    "        \n",
    "            print('\\nWord identified {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
