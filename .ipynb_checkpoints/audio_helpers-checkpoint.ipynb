{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyML keyword spotting helper functions\n",
    "Some functions useful for handling audio data, used in TinyML keyword spotting exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio files\n",
    "\n",
    "As I was having some problems with the HTML audio recording code, I recorded my keyword samples with Audacity, \n",
    "and then upload them with this little snippet.\n",
    "\n",
    "How to use: \n",
    "\n",
    "```python\n",
    "audio, sr = get_audio('my_file.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as wav_read\n",
    "def get_audio(file):\n",
    "    '''return sample rate and audio data'''\n",
    "    sr, audio = wav_read(file)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV file converter\n",
    "\n",
    "With Audacity or similar software, the default settings are often the CD quality, that is 44.1kHz stereo, or in some cases even 48kHz stereo 24/32 bit.  \n",
    "This code snippet allows easy conversion to a lower (or upper) sample rate `resampled_sr` and/or mix down to `mono` channel, maintaining the bit resolution.\n",
    "\n",
    "How to use:\n",
    "\n",
    "```python\n",
    "wave_converter('my_file1.wav', mix2mono = True)\n",
    "'''output file \"resampled_my_file1.wav\", mono, 16000 Hz sample rate'''\n",
    "\n",
    "wave_converter('my_file2.wav', resampled_sr = 8000, prefix = \"small_\")\n",
    "'''output file \"small_my_file2.wav\", 8000 Hz sample rate, number of channels unchanged (e.g. a stereo file\n",
    "will remain stereo)'''\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "import librosa\n",
    "\n",
    "def wave_converter(filename, resampled_sr=16000, prefix=\"resampled_\", mix2mono = False):\n",
    "\n",
    "    '''\n",
    "    Resample WAV soundfile to a different sample rate.\n",
    "    \n",
    "        Input: original sound file\n",
    "        Output: resampled sound file\n",
    "        Parameters: \n",
    "            - name of the file to be converted, \n",
    "            - destination sample rate, default = 16kHz\n",
    "            - prefix to identify resampled files\n",
    "            - mix to mono channel, default = False (leave as-is)\n",
    "            \n",
    "        Notes: for simplicity it needs to be run in the folder with the files we are converting\n",
    "    '''    \n",
    "    \n",
    "    resampled_file = prefix + filename \n",
    "    origin_sr, origin_data = wavfile.read(filename)\n",
    "    origin_type = origin_data.dtype\n",
    "    \n",
    "    resampled_data = librosa.resample(origin_data.T.astype('float'), origin_sr, resampled_sr) # transpose array to librosa shape\n",
    "    if mix2mono == True:\n",
    "        resampled_data = librosa.to_mono(resampled_data)        \n",
    "    resampled_data = resampled_data.T.astype(origin_type) # transpose back to scipy.io.wavfile shape\n",
    "    \n",
    "    wavfile.write(resampled_file, resampled_sr, resampled_data)\n",
    "    \n",
    "    # print('Resampled wavefile saved to {}'.format(resampled_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch file conversion\n",
    "\n",
    "In case you want to try training the model with lower sample rate (DESTINATION_SR), this helps processing the entire dataset folder (ORIGINAL_DIR), recreating the folder structure in another folder (DESTINATION_DIR) at the same level. \n",
    "The `wave_converter` function was modified to make batch processing easier.\n",
    "\n",
    "When doing this in JupyterLab, it helps to increase the IOPub message rate (default at 1000 msg/s), by setting the config variable at launch:\n",
    "\n",
    "```bash\n",
    "jupyter lab --Notebook.App.iopub_msg_rate_limit=100000 \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the parameters\n",
    "\n",
    "ORIGINAL_DIR = 'dataset' # this is where we store our subfolders with WAV files\n",
    "PREFIX = '8k_' # prefix to distinguish the folder and also the processed files\n",
    "DESTINATION_DIR = PREFIX+ORIGINAL_DIR\n",
    "DESTINATION_SR = 8000 # desired sample rate in Hertz\n",
    "FILE_TYPE = '.wav' # do not change this\n",
    "MIX2MONO = False # if set to False, will leave files in their original format, either stereo or mono. Set to True will convert stereo files to mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_converter_v2(file_path, resampled_sr=16000, prefix=\"resampled_\", mix2mono = False):\n",
    "\n",
    "    '''\n",
    "    Modified version of the wave_converter function, more suitable for batch processing.\n",
    "    \n",
    "    Resample WAV soundfile to a different sample rate.\n",
    "    \n",
    "        Input: original sound file path\n",
    "        Output: resampled sound data, sample rate and file \n",
    "        name\n",
    "        Parameters: \n",
    "            - name of the file to be converted, \n",
    "            - destination sample rate, default = 16kHz\n",
    "            - prefix to identify resampled files\n",
    "            - mix to mono channel, default = False (leave as-is)        \n",
    "    '''    \n",
    "       \n",
    "    origin_sr, origin_data = wavfile.read(file_path)\n",
    "    origin_type = origin_data.dtype\n",
    "    \n",
    "    filename = os.path.split(file_path)[1] # get the actual file name\n",
    "    resampled_file = prefix + filename \n",
    "    \n",
    "    resampled_data = librosa.resample(origin_data.T.astype('float'), origin_sr, resampled_sr) # transpose array to librosa shape\n",
    "    if mix2mono == True:\n",
    "        resampled_data = librosa.to_mono(resampled_data)        \n",
    "    resampled_data = resampled_data.T.astype(origin_type) # transpose back to scipy.io.wavfile shape\n",
    "    \n",
    "    return resampled_file, resampled_sr, resampled_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 8k_dataset folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebelgrau/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:18: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 105835 files in 38 folders.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "file_counter = 0\n",
    "folder_counter = 0\n",
    "\n",
    "if not os.path.exists(DESTINATION_DIR): # check if destination folder exists\n",
    "    os.mkdir(DESTINATION_DIR)\n",
    "    print('created {} folder'.format(DESTINATION_DIR))\n",
    "\n",
    "for folder in os.listdir(ORIGINAL_DIR):\n",
    "        \n",
    "    if os.path.isdir(os.path.join(ORIGINAL_DIR,folder)): # process only folders\n",
    "        \n",
    "        folder_counter += 1\n",
    "        \n",
    "        for file in os.listdir(os.path.join(ORIGINAL_DIR,folder)):\n",
    "            \n",
    "            file_path = os.path.join(ORIGINAL_DIR, folder, file)\n",
    "            \n",
    "            if os.path.isfile(file_path) and file.endswith(FILE_TYPE): # check if it's a wav file\n",
    "\n",
    "                resampled_file, resampled_sr, resampled_data = wave_converter_v2(\n",
    "                                                                file_path, \n",
    "                                                                resampled_sr=DESTINATION_SR, \n",
    "                                                                prefix=PREFIX, \n",
    "                                                                mix2mono = MIX2MONO)\n",
    "\n",
    "                if not os.path.exists(os.path.join(DESTINATION_DIR, folder)): # create a subfolder if necessary\n",
    "                    os.mkdir(os.path.join(DESTINATION_DIR, folder))\n",
    "\n",
    "                resampled_file_path = os.path.join(DESTINATION_DIR, folder, resampled_file)\n",
    "\n",
    "                wavfile.write(resampled_file_path, resampled_sr, resampled_data)\n",
    "\n",
    "                file_counter += 1\n",
    "                \n",
    "                # print(\"Saved converted file {}\".format(resampled_file_path))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Finished processing {} files in {} folders.\".format(file_counter, folder_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch inference testing\n",
    "\n",
    "Helper function for testing your own audio samples with the model here:\n",
    "\n",
    "https://github.com/tinyMLx/colabs/blob/master/3-5-13-PretrainedModel.ipynb\n",
    "\n",
    "\n",
    "__Assumptions:__\n",
    "\n",
    "* your samples are saved in a folder, and the file names follow a specific pattern `audio_a_cat01.wav`: \n",
    "    * `a` is the speaker identifier, \n",
    "    * `cat` is the actual keyword, \n",
    "    * `01` is the sample number, assuming we have multiple samples for each word.\n",
    "\n",
    "* `run_tflite_inference_singleFile` function, `WANTED_WORDS` and `MODEL_TFLITE` variables are already defined.\n",
    "\n",
    "* `run_tflite_inference_singleFile` function is modified to return the top_prediction_str and model_type variables:\n",
    "\n",
    "```python\n",
    "def run_tflite_inference_singleFile(tflite_model_path, custom_audio, sr_custom_audio, model_type=\"Float\"):\n",
    "  \n",
    "  # (function code here) \n",
    "  #  \n",
    "  # print('%s model guessed the value to be %s' % (model_type, top_prediction_str))\n",
    "\n",
    "  return model_type, top_prediction_str # used in the batch script later\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"Quantized\"\n",
    "\n",
    "SPEAKERS = {'a': 'Alice', 'b': 'Bob'}\n",
    "\n",
    "SAMPLES_DIR = 'speech_custom'\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "for file in os.listdir(SAMPLES_DIR):\n",
    "    if os.path.isdir(file): # skip folders, process files only \n",
    "        pass\n",
    "    else:                        \n",
    "        try:\n",
    "            speaker, word, number = re.findall('custom_(\\w)_([a-z]+)(\\d+).wav', file)[0] # extract info                                    \n",
    "        except:\n",
    "            print(\"File name {} is not in a correct format\".format(file))\n",
    "            # pass\n",
    "        sample_name = file[:-4] # create variable names\n",
    "        sample_rate = 'sr_' + sample_name # create variable names\n",
    "        globals()[sample_name], globals()[sample_rate] = get_audio(os.path.join(SAMPLES_DIR, file)) # define variables\n",
    "        \n",
    "        if word in [word for word in WANTED_WORDS.split(',')]: # WANTED_WORDS and MODEL_TFLITE defined earlier\n",
    "    \n",
    "            model_type, top_prediction_str = run_tflite_inference_singleFile(MODEL_TFLITE, globals()[sample_name], globals()[sample_rate], model_type=MODEL_TYPE)\n",
    "        \n",
    "            if top_prediction_str.upper() == word.upper():\n",
    "                result = \"CORRECTLY\"\n",
    "            else:\n",
    "                result = \"INCORRECTLY\"\n",
    "                        \n",
    "            print('\\nWord: {},\\nSpeaker: {},\\nSample number: {},\\nFile: {}'.format(word.upper(), speakers[speaker], number, file))\n",
    "        \n",
    "            print(\"\\n{} model guessed the value to be {}.\".format(model_type, top_prediction_str.upper()))\n",
    "        \n",
    "            print('\\nWord identified {}\\n'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
